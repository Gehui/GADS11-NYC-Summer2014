{
 "metadata": {
  "name": "",
  "signature": "sha256:d210608cfe92f1e4b987a577c887d36bdc76cc302c6783b40d002f7a2c5d7b71"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "np.random.seed(1) #for consistency\n",
      "\n",
      "mu_vec1 = np.array([0,0,0])\n",
      "cov_mat1 = np.identity(3)\n",
      "class1_sample = np.random.multivariate_normal(mu_vec1, cov_mat1, 20).T\n",
      "\n",
      "mu_vec2 = np.array([1,1,1])\n",
      "cov_mat2 = np.identity(3)\n",
      "class2_sample = np.random.multivariate_normal(mu_vec2, cov_mat2, 20).T\n",
      "\n",
      "# Plotting our data in 3-dimensions! #\n",
      "from matplotlib import pyplot as plt\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "from mpl_toolkits.mplot3d import proj3d\n",
      "\n",
      "fig = plt.figure(figsize=(10,10))\n",
      "ax = fig.add_subplot(111, projection='3d')\n",
      "plt.rcParams['legend.fontsize'] = 10\n",
      "ax.plot(class1_sample[0,:], class1_sample[1,:],\\\n",
      "    class1_sample[2,:], 'o', markersize=8, color='blue', alpha=0.5, label='class1')\n",
      "ax.plot(class2_sample[0,:], class2_sample[1,:],\\\n",
      "    class2_sample[2,:], '^', markersize=8, alpha=0.5, color='red', label='class2')\n",
      "\n",
      "plt.title('Samples for classes 1 & 2')\n",
      "ax.legend(loc='upper right')\n",
      "plt.show()\n",
      "\n",
      "\n",
      "### COMPUTING THE SCATTER MATRIX ###\n",
      "\n",
      "# First we need the mean vector #\n",
      "mean_vector = np.mean(all_samples, axis=1)\n",
      "mean_vector\n",
      "\n",
      "scatter_matrix = np.zeros((3,3))\n",
      "\n",
      "for i in range(all_samples.shape[1]):\n",
      "    scatter_matrix += (all_samples[:,i].reshape(3,1) - mean_vector).dot((all_samples[:,i].reshape(3,1) - mean_vector).T)\n",
      "\n",
      "scatter_matrix\n",
      "\n",
      "### COMPUTING THE COVARIANCE MATRIX ###\n",
      "\n",
      "# Removing class labels, remember this is UNsupervised learning #\n",
      "\n",
      "all_samples = np.concatenate((class1_sample, class2_sample), axis=1)\n",
      "assert all_samples.shape == (3,40), \"The matrix has not the dimensions 3x40\"\n",
      "\n",
      "cov_mat = np.cov([all_samples[0,:],all_samples[1,:],all_samples[2,:]])\n",
      "\n",
      "cov_mat\n",
      "\n",
      "### COMPUTING EIGENVECTORS AND CORRESPONDING EIGENVALUES ###\n",
      "\n",
      "# For the scatter matrix\n",
      "eig_val_sc, eig_vec_sc = np.linalg.eig(scatter_matrix)\n",
      "\n",
      "# For the covariance matrix\n",
      "eig_val_cov, eig_vec_cov = np.linalg.eig(cov_mat)\n",
      "\n",
      "'''\n",
      "To show the eigenvectors are identical whether we derived them from the scatter or the \n",
      "covariance matrix, let's put an assert statement into the code. Also, we will see the \n",
      "eigenvalues were scaled by the factor 39 when we derived it from the scatter matrix.\n",
      "'''\n",
      "for i in range(len(eig_val_sc)):\n",
      "    eigvec_sc = eig_vec_sc[:,i].reshape(1,3).T\n",
      "    eigvec_cov = eig_vec_cov[:,i].reshape(1,3).T\n",
      "    assert eigvec_sc.all() == eigvec_cov.all(), 'Eigenvectors are not identical'\n",
      "    print('Eigenvector {}: \\n{}'.format(i+1, eigvec_sc))\n",
      "    print('Eigenvalue {} from scatter matrix: {}'.format(i+1, eig_val_sc[i]))\n",
      "    print('Eigenvalue {} from covariance matrix: {}'.format(i+1, eig_val_cov[i]))\n",
      "    print('Scaling factor: ', eig_val_sc[i]/eig_val_cov[i])\n",
      "    print(40 * '-')\n",
      "\n",
      "# Visualizing the eigenvectors #\n",
      "from matplotlib import pyplot as plt\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "from mpl_toolkits.mplot3d import proj3d\n",
      "from matplotlib.patches import FancyArrowPatch\n",
      "\n",
      "class Arrow3D(FancyArrowPatch):\n",
      "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
      "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
      "        self._verts3d = xs, ys, zs\n",
      "    def draw(self, renderer):\n",
      "        xs3d, ys3d, zs3d = self._verts3d\n",
      "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
      "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
      "        FancyArrowPatch.draw(self, renderer)\n",
      "\n",
      "fig = plt.figure(figsize=(7,7))\n",
      "ax = fig.add_subplot(111, projection='3d')\n",
      "ax.plot(all_samples[0,:], all_samples[1,:], all_samples[2,:], 'o', markersize=8, color='green', alpha=0.2)\n",
      "ax.plot([mean_x], [mean_y], [mean_z], 'o', markersize=10, color='red', alpha=0.5)\n",
      "for v in eig_vec_sc.T:\n",
      "    a = Arrow3D([mean_x, v[0]], [mean_y, v[1]], [mean_z, v[2]], mutation_scale=20, lw=3, arrowstyle=\"-|>\", color=\"r\")\n",
      "    ax.add_artist(a)\n",
      "\n",
      "ax.set_xlabel('x_values')\n",
      "ax.set_ylabel('y_values')\n",
      "ax.set_zlabel('z_values')\n",
      "plt.title('Eigenvectors')\n",
      "plt.show()\n",
      "\n",
      "### CHOOSING OUR EIGENVECTORS ###\n",
      "\n",
      "# Make a list of (eigenvalue, eigenvector) tuples and sort them#\n",
      "eig_pairs = [(np.abs(eig_val_sc[i]), eig_vec_sc[:,i]) for i in range(len(eig_val_sc))]\n",
      "eig_pairs.sort(reverse=True)\n",
      "eig_pairs\n",
      "\n",
      "\n",
      "### TRANSFORMING THE SAMPLES ONTO THE NEW SUBSPACE ###\n",
      "transformed = matrix_w.T.dot(all_samples)\n",
      "transformed\n",
      "\n",
      "plt.plot(transformed[0,0:20], transformed[1,0:20],'o', markersize=7, color='blue', alpha=0.5, label='class1')\n",
      "plt.plot(transformed[0,20:40], transformed[1,20:40],'^', markersize=7, color='red', alpha=0.5, label='class2')\n",
      "plt.xlim([-4,4])\n",
      "plt.ylim([-4,4])\n",
      "plt.xlabel('x_values')\n",
      "plt.ylabel('y_values')\n",
      "plt.legend()\n",
      "plt.title('Transformed samples with class labels')\n",
      "plt.show()\n",
      "\n",
      "\n",
      "'''\n",
      "NOW THE EASY WAY, WITH SCI-KIT LEARN\n",
      "'''\n",
      "from sklearn.decomposition import PCA as sklearnPCA\n",
      "\n",
      "sklearn_pca = sklearnPCA(n_components=2)\n",
      "sklearn_transf = sklearn_pca.fit_transform(all_samples.T)\n",
      "\n",
      "plt.plot(sklearn_transf[0:20,0],sklearn_transf[0:20,1],'o', markersize=7, color='blue', alpha=0.5, label='class1')\n",
      "plt.plot(sklearn_transf[20:40,0], sklearn_transf[20:40,1],'^', markersize=7, color='red', alpha=0.5, label='class2')\n",
      "plt.xlabel('x_values')\n",
      "plt.ylabel('y_values')\n",
      "plt.xlim([-4,4])\n",
      "plt.ylim([-4,4])\n",
      "plt.legend()\n",
      "plt.title('Transformed samples with class labels from sklearnPCA')\n",
      "plt.show()\n",
      "\n",
      "# That looks like the opposite of our original graph, let's fix that #\n",
      "sklearn_transf = sklearn_transf * (-1)\n",
      "plt.plot(sklearn_transf[0:20,0],sklearn_transf[0:20,1],'o', markersize=7, color='blue', alpha=0.5, label='class1')\n",
      "plt.plot(sklearn_transf[20:40,0], sklearn_transf[20:40,1],'^', markersize=7, color='red', alpha=0.5, label='class2')\n",
      "plt.xlabel('x_values')\n",
      "plt.ylabel('y_values')\n",
      "plt.xlim([-4,4])\n",
      "plt.ylim([-4,4])\n",
      "plt.legend()\n",
      "plt.title('Transformed samples via sklearn.decomposition.PCA')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'all_samples' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-3dc3df96af31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# First we need the mean vector #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmean_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mmean_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'all_samples' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}